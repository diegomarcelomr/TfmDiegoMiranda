{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0k6TRvPoJUz7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Desinstalar versiones potencialmente incompatibles\n",
        "!pip uninstall -y transformers\n",
        "!pip uninstall -y accelerate\n",
        "!pip install -q --upgrade pip\n",
        "\n",
        "# Instalar versiones correctas y compatibles con MiniCPM-V-2_6\n",
        "!pip install --no-cache-dir \\\n",
        "  torch==2.1.2 \\\n",
        "  torchvision==0.16.2 \\\n",
        "  transformers==4.40.0 \\\n",
        "  Pillow==10.1.0 \\\n",
        "  sentencepiece==0.1.99 \\\n",
        "  decord==0.6.0 \\\n",
        "  accelerate==0.30.1 \\\n",
        "  bitsandbytes==0.43.1 \\\n",
        "  peft==0.10.0\n",
        "\n",
        "# Reinicia el entorno manualmente después de esto para evitar errores residuales:\n",
        "# Menu: Entorno de ejecución → Reiniciar entorno\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEoE5FGHH69s"
      },
      "outputs": [],
      "source": [
        "#Accedemos a Google Drive, ya que ahi se encuentra cargada las imágenes y el archivo JSON\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CWlJ_MvZ9tP"
      },
      "outputs": [],
      "source": [
        "#Inicializo el HUgging Face\n",
        "from huggingface_hub import login,notebook_login\n",
        "\n",
        "login(token=\"XXXXXXXXXX\") #Aqui se pone el Token que brinda el Hugging Face\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "776OPD_fK08U"
      },
      "outputs": [],
      "source": [
        "# Importación de las librerías necesarias\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Cargo el modelo\n",
        "model = AutoModel.from_pretrained(\n",
        "    'openbmb/MiniCPM-V-2_6',\n",
        "    trust_remote_code=True,\n",
        "    attn_implementation='sdpa',\n",
        "    torch_dtype=torch.bfloat16,\n",
        ").cuda()\n",
        "model = model.eval()\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2_6', trust_remote_code=True)\n",
        "\n",
        "# Configuración LoRA\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# Cargar dataset\n",
        "with open(\"/content/drive/MyDrive/train_human.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Procesamiento de cada ejemplo del dataset\n",
        "image_dir = \"/content/drive/MyDrive/png\"\n",
        "examples = []\n",
        "for item in data:\n",
        "    img_path = os.path.join(image_dir, item[\"imgname\"])\n",
        "    if not os.path.exists(img_path):\n",
        "        continue\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    question = item[\"query\"]\n",
        "    answer = item[\"label\"]\n",
        "    examples.append({\"image\": image, \"question\": question, \"answer\": answer})\n",
        "\n",
        "# Loop de entrenamiento\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    print(f\"Epoch {epoch+1}/3\")\n",
        "    for i, sample in enumerate(examples):\n",
        "        prompt = f\"<image>\\nQuestion: {sample['question']}\\nAnswer:\"\n",
        "        msgs = [{\"role\": \"user\", \"content\": [sample[\"image\"], sample[\"question\"]]}]\n",
        "        labels = tokenizer(sample[\"answer\"], return_tensors=\"pt\")[\"input_ids\"].cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byNjvesJYOHh"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Ruta a la imagen externa\n",
        "image_path = \"/content/PRUEBAS/engañosa6.png\"\n",
        "\n",
        "# Cargar imagen\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Pregunta\n",
        "question = \"First, describe what you see: axes, ranges, labels, colors, scale. Second, critically analyze each element: Are there truncated axes? Misleading colors? Is there a logarithmic scale without warning?Finally, based on the above, is the graph misleading? Detail which elements are misleading. \"\n",
        "\n",
        "# Construir input\n",
        "msgs = [{\"role\": \"user\", \"content\": [image, question]}]\n",
        "\n",
        "# Ejecutar inferencia\n",
        "with torch.no_grad():\n",
        "    response = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"Pregunta:\", question)\n",
        "print(\"Respuesta del modelo:\", response)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
